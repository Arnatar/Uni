OPTIMIZE FLAGS -----------------------------------------------------------------

keine Optimierung : 46.02sec
-O1               : 10.06sec
-O2               : 10.12sec
-O3               :  7.72sec

GPROF --------------------------------------------------------------------------

  %   cumulative   self              self     total
 time   seconds   seconds    calls   s/call   s/call  name
 94.43     37.34    37.34        1    37.34    39.20  calculate
  4.71     39.20     1.86 1088472064     0.00     0.00  getResiduum
  0.99     39.59     0.39        1     0.39     0.39  initMatrices
  0.00     39.59     0.00        4     0.00     0.00  allocateMemory
  0.00     39.59     0.00        1     0.00     0.00  AskParams
  0.00     39.59     0.00        1     0.00     0.00  DisplayMatrix
  0.00     39.59     0.00        1     0.00     0.00  allocateMatrices
  0.00     39.59     0.00        1     0.00     0.00  displayStatistics
  0.00     39.59     0.00        1     0.00     0.00  freeMatrices
  0.00     39.59     0.00        1     0.00     0.00  initVariables

Call graph (explanation follows)

granularity: each sample hit covers 2 byte(s) for 0.03% of 39.59 seconds

index % time    self  children    called     name
                                                 <spontaneous>
[1]    100.0    0.00   39.59                 main [1]
               37.34    1.86       1/1           calculate [2]
                0.39    0.00       1/1           initMatrices [4]
                0.00    0.00       1/1           AskParams [6]
                0.00    0.00       1/1           allocateMatrices [8]
                0.00    0.00       1/1           initVariables [11]
                0.00    0.00       1/1           displayStatistics [9]
                0.00    0.00       1/1           DisplayMatrix [7]
                0.00    0.00       1/1           freeMatrices [10]
-----------------------------------------------
               37.34    1.86       1/1           main [1]
[2]     99.0   37.34    1.86       1         calculate [2]
                1.86    0.00 1088472064/1088472064     getResiduum [3]
-----------------------------------------------
                1.86    0.00 1088472064/1088472064     calculate [2]
[3]      4.7    1.86    0.00 1088472064         getResiduum [3]
-----------------------------------------------
                0.39    0.00       1/1           main [1]
[4]      1.0    0.39    0.00       1         initMatrices [4]
-----------------------------------------------
                0.00    0.00       4/4           allocateMatrices [8]
[5]      0.0    0.00    0.00       4         allocateMemory [5]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[6]      0.0    0.00    0.00       1         AskParams [6]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[7]      0.0    0.00    0.00       1         DisplayMatrix [7]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[8]      0.0    0.00    0.00       1         allocateMatrices [8]
                0.00    0.00       4/4           allocateMemory [5]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[9]      0.0    0.00    0.00       1         displayStatistics [9]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[10]     0.0    0.00    0.00       1         freeMatrices [10]
-----------------------------------------------
                0.00    0.00       1/1           main [1]
[11]     0.0    0.00    0.00       1         initVariables [11]
-----------------------------------------------

Index by function name

   [6] AskParams               [2] calculate               [4] initMatrices
   [7] DisplayMatrix           [9] displayStatistics      [11] initVariables
   [8] allocateMatrices       [10] freeMatrices
   [5] allocateMemory          [3] getResiduum

------------------------
Fazit: calculate ist das Bottleneck.


PERF ---------------------------------------------------------------------------
Performance counter stats for './partdiff-seq 1 2 128 1 2 1024':

      46183.400146      task-clock (msec)         #    1.001 CPUs utilized
                84      context-switches          #    0.002 K/sec
                 6      cpu-migrations            #    0.000 K/sec
               144      page-faults               #    0.003 K/sec
   115,089,534,410      cycles                    #    2.492 GHz
    65,290,334,124      stalled-cycles-frontend   #   56.73% frontend cycles idle
   <not supported>      stalled-cycles-backend
   192,768,319,497      instructions              #    1.67  insns per cycle
                                                  #    0.34  stalled cycles per insn
     8,722,580,775      branches                  #  188.868 M/sec
         1,209,771      branch-misses             #    0.01% of all branches

      46.132302971 seconds time elapsed

Interpretation:

- ein context-switch passiert, wenn das Betriebssystem den Prozess für andere Aktivitaeten unterbricht. 84x in 46sec erscheint uns aber nicht so viel, von daher dürfte das hier nicht der culprit sein und außerdem haetten wir eh keinen Einfluss darauf.

- 56% stalled frontend cycles ist schlecht: das Frontend ist der Teil der Prozessor-Pipeline, der für die fetch und decode phase verantwortlich ist. "Stalled" heißt, dass das Frontend auf das Backend warten muss, wenn dieses noch rechnet. Das Frontend ist also 56% der Zeit untaetig.

- 1.67 Instructions/Cycle ist möglich wegen Pipelining. Diese Ausbeute kann sicherlich durch Optimierungen im Code verbessert werden.

Processor pipeline is composed of many stages: the front-end is a group of these stages which is responsible for the fetch and decode phases, while the back-end executes the instructions. There is a buffer between front-end and back-end, so when the former is stalled the latter can still have some work to do.

- branches denotiert die Anzahl an Verzweigungen im Code (bspw. if-statements). Die CPU kann versuchen, den wahrscheinlichsten Ausgang einer solchen Verzweigung vorherzusagen ("speculative execution" und so die Auslastung der Pipeline zu optimieren. 'branch-misses' beschreibt, wie haeufig dies "schief gegangen" ist. 0.01% ist sehr gut.



Optimisation im Code -----------------------------------------------------------

[1] ----------------------------------------------------------------------------

Die Indizes im inner loop von calculate sind vertauscht. Dies ist der Fix:
     /* over all rows */
-    for (j = 1; j < N; j++)
+    for (i = 1; i < N; i++)
     {
             /* over all columns */
-            for (i = 1; i < N; i++)
+            for (j = 1; j < N; j++)

Begründung: die Iteration der Daten sollte sich an der Anordnung dieser im Cache orientieren. Die rows sollten "von links nach rechts" durchiteriert werden; in der originalen Implementation erfolgt die Iteration hingegen "von oben nach unten", was zu cache misses ohne Ende führt.
Speedup: 46sec -> 34.6sec. (+32%)
56.73% -> 42.59% frontend cycles idle.


[2] ----------------------------------------------------------------------------

Die lokale Variable `korrektur` ist überflüssig.

    residuum = getResiduum(arguments, options, i, j, star);
-   korrektur = residuum;
+   Matrix[m1][i][j] = Matrix[m2][i][j] + residuum;
+
    residuum = (residuum < 0) ? -residuum : residuum;
    maxresiduum = (residuum < maxresiduum) ? maxresiduum : residuum;

-   Matrix[m1][i][j] = Matrix[m2][i][j] + korrektur;

Der Performance-Gewinn ist allerdings kaum existent, bei -O3 gib es 1ms weniger..
